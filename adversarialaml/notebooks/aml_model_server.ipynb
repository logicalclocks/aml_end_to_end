{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook we will perform inference wheater embeddings vector represents subgraph of normal or  anomalous transaction. using our anomaly detection model     \n",
    "---\n",
    "**NOTE**: \n",
    "\n",
    "In real life scenarios financial transaction are dynamically evolving graphs. Performing anomaly detection inference on graph embeddings in live Transaction Monitoring Systems will require 1st to update the graph and node representations after new transactions arrive. Recomputing entire graph for every newly arrived transaction will lead to unaxeptable delayes and even monitoring system failure. This problem  will be more sever if large amount of updates happen in a short time window.\n",
    "\n",
    "Contact us at Logical Clocks and we will help you to setup end to end graph based deep anomaly detection live Transaction Monitoring Systems. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>60</td><td>application_1612947411090_0005</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://resourcemanager.service.consul:8088/proxy/application_1612947411090_0005/\">Link</a></td><td><a target=\"_blank\" href=\"http://amlsim-worker-1.internal.cloudapp.net:8042/node/containerlogs/container_e08_1612947411090_0005_01_000001/amlsim__meb10179\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "<pyspark.sql.session.SparkSession object at 0x7f36f025bf90>"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from hops import model\n",
    "from hops.model import Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Model Repository for best anomaly detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME=\"gansimaml\"\n",
    "EVALUATION_METRIC=\"metric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model.get_best_model(MODEL_NAME, EVALUATION_METRIC, Metric.MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: gansimaml\n",
      "Model version: 1\n",
      "{'metric': '6.566298961639404'}"
     ]
    }
   ],
   "source": [
    "print('Model name: ' + best_model['name'])\n",
    "print('Model version: ' + str(best_model['version']))\n",
    "print(best_model['metrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model Serving of Exported Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hops import serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'gansimaml'"
     ]
    }
   ],
   "source": [
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    }
   ],
   "source": [
    "best_model['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/Models/gansimaml'"
     ]
    }
   ],
   "source": [
    "model_path=\"/Models/\" + best_model['name']\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a serving for model gansimaml ...\n",
      "Serving for model gansimaml successfully created"
     ]
    }
   ],
   "source": [
    "# Create serving\n",
    "model_path=\"/Models/\" + best_model['name']\n",
    "model_path\n",
    "response = serving.create_or_update(artifact_path=model_path, serving_name=MODEL_NAME, serving_type=\"TENSORFLOW\", \n",
    "                                 model_version=best_model['version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gansimaml"
     ]
    }
   ],
   "source": [
    "# List all available servings in the project\n",
    "for s in serving.get_all():\n",
    "    print(s.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Stopped'"
     ]
    }
   ],
   "source": [
    "# Get serving status\n",
    "serving.get_status(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Model Serving Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting serving with name: gansimaml...\n",
      "Serving with name: gansimaml successfully started"
     ]
    }
   ],
   "source": [
    "if serving.get_status(MODEL_NAME) == 'Stopped':\n",
    "    serving.start(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while serving.get_status(MODEL_NAME) != \"Running\":\n",
    "    time.sleep(5) # Let the serving startup correctly\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Prediction Requests to the Served Model using Hopsworks REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully."
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "# Create a connection\n",
    "connection = hsfs.connection()\n",
    "# Get the feature store handle for the project's feature store\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_td = fs.get_training_dataset(\"eval_td\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                 mms|\n",
      "+------+--------------------+\n",
      "|   0.0|[-0.4065766, -0.2...|\n",
      "|   0.0|[-0.37156734, -0....|\n",
      "|   0.0|[-0.3331596, -0.0...|\n",
      "|   0.0|[-0.30843127, -0....|\n",
      "|   0.0|[-0.26306894, -0....|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "eval_td.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_server(model_name, input):\n",
    "    data = {\"signature_name\": \"serving_default\", \"inputs\": [input]}\n",
    "    return serving.make_inference_request(model_name, data)['outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_df = eval_td.read()\\\n",
    "                   .rdd.map(lambda x: (x.target,model_server(MODEL_NAME, np.array(x.mms).tolist()))).map(lambda f: (f[0],f[1][0]))\\\n",
    "                   .toDF().toDF(\"target\",\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|target|     score|\n",
      "+------+----------+\n",
      "|   0.0|16.3264771|\n",
      "|   0.0|32.0050278|\n",
      "|   0.0|8.96398163|\n",
      "|   0.0|9.12968445|\n",
      "|   0.0|10.6783476|\n",
      "|   0.0|3.54688883|\n",
      "|   0.0|2.80013108|\n",
      "|   0.0|5.92823219|\n",
      "|   0.0|6.65167141|\n",
      "|   0.0|7.45862341|\n",
      "|   0.0| 3.1319952|\n",
      "|   0.0|17.8965607|\n",
      "|   0.0|16.2934685|\n",
      "|   0.0|7.09727764|\n",
      "|   0.0|7.13687325|\n",
      "|   0.0|7.36101723|\n",
      "|   0.0|   6.18361|\n",
      "|   0.0|5.83205318|\n",
      "|   0.0|7.72574568|\n",
      "|   0.0|13.0513754|\n",
      "+------+----------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "scored_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|target|     score|\n",
      "+------+----------+\n",
      "|   1.0|   9.60008|\n",
      "|   1.0|13.9220219|\n",
      "|   1.0|12.3727131|\n",
      "|   1.0|8.70950413|\n",
      "|   1.0|11.6165619|\n",
      "|   1.0|15.2314949|\n",
      "|   1.0|11.2959318|\n",
      "|   1.0|11.9945049|\n",
      "|   1.0|13.9294739|\n",
      "|   1.0|9.27066612|\n",
      "|   1.0|18.3138161|\n",
      "|   1.0|17.8045673|\n",
      "|   1.0|7.22413254|\n",
      "|   1.0|26.7689133|\n",
      "|   1.0|11.7971725|\n",
      "|   1.0|12.8136816|\n",
      "|   1.0|10.2775126|\n",
      "|   1.0|8.90372562|\n",
      "|   1.0|7.90231133|\n",
      "|   1.0|10.8522491|\n",
      "+------+----------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "scored_df.where(scored_df.target == 1.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|target|     score|\n",
      "+------+----------+\n",
      "|   0.0|16.3264771|\n",
      "|   0.0|32.0050278|\n",
      "|   0.0|8.96398163|\n",
      "|   0.0|9.12968445|\n",
      "|   0.0|10.6783476|\n",
      "|   0.0|3.54688883|\n",
      "|   0.0|2.80013108|\n",
      "|   0.0|5.92823219|\n",
      "|   0.0|6.65167141|\n",
      "|   0.0|7.45862341|\n",
      "|   0.0| 3.1319952|\n",
      "|   0.0|17.8965607|\n",
      "|   0.0|16.2934685|\n",
      "|   0.0|7.09727764|\n",
      "|   0.0|7.13687325|\n",
      "|   0.0|7.36101723|\n",
      "|   0.0|   6.18361|\n",
      "|   0.0|5.83205318|\n",
      "|   0.0|7.72574568|\n",
      "|   0.0|13.0513754|\n",
      "+------+----------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "scored_df.where(scored_df.target == 0.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}