{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>0</td><td>application_1613331100983_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://amlsim-master.internal.cloudapp.net:8088/proxy/application_1613331100983_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://amlsim-worker-1.internal.cloudapp.net:8042/node/containerlogs/container_e03_1613331100983_0001_01_000001/amlsim__meb10179\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "<pyspark.sql.session.SparkSession object at 0x7fd4babfff10>"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType, StringType\n",
    "import hsfs\n",
    "from hops import hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_2_code(input_str):\n",
    "    x = input_str.split(\"-\")[0]\n",
    "    if (x == \"CASH_IN\"):\n",
    "        node_type = 0\n",
    "    elif (x == \"CASH_OUT\"):\n",
    "        node_type = 1\n",
    "    elif (x == \"DEBIT\"):\n",
    "        node_type = 2\n",
    "    elif (x == \"PAYMENT\"):\n",
    "        node_type = 3\n",
    "    elif (x == \"TRANSFER\"):\n",
    "        node_type = 4\n",
    "    elif (x == \"DEPOSIT\"):\n",
    "        node_type = 4        \n",
    "    else:\n",
    "        node_type = 99\n",
    "    return node_type\n",
    "\n",
    "def party_2_code(x):\n",
    "    if (x == \"Organization\"):\n",
    "        party_type = 0\n",
    "    elif (x == \"Individual\"):\n",
    "        party_type = 1\n",
    "    else:    \n",
    "        party_type = 99\n",
    "    return party_type\n",
    "\n",
    "def timestamp_2_time(x):\n",
    "    dt_obj = datetime.strptime(str(x), '%Y-%m-%d %H:%M:%S')\n",
    "    return dt_obj.strftime(\"%b-%d\") \n",
    "\n",
    "action_2_code_udf = F.udf(action_2_code)\n",
    "party_2_code_udf = F.udf(party_2_code)\n",
    "timestamp_2_time_udf = F.udf(timestamp_2_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a connection to Hopsworks feature store (hsfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully."
     ]
    }
   ],
   "source": [
    "# Create a connection\n",
    "connection = hsfs.connection()\n",
    "# Get the feature store handle for the project's feature store\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load transactions datasets as spark dataframe and perform feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = spark.read\\\n",
    "             .option(\"inferSchema\", \"true\")\\\n",
    "             .option(\"header\", \"true\")\\\n",
    "             .format(\"csv\")\\\n",
    "             .load(\"hdfs:///Projects/{}/Resources/transactions.csv\".format(hdfs.project_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------+-------------------+--------+--------+\n",
      "|tran_id|         tx_type|base_amt|     tran_timestamp|     src|     dst|\n",
      "+-------+----------------+--------+-------------------+--------+--------+\n",
      "|    496| TRANSFER-FanOut|  858.77|2020-01-01 00:00:00|3aa9646b|1e46e726|\n",
      "|   1342| TRANSFER-Mutual|  386.86|2020-01-01 00:00:00|49203bc3|a74d1101|\n",
      "|   1580| TRANSFER-FanOut|  616.43|2020-01-02 00:00:00|616d4505|99af2455|\n",
      "|   2866| TRANSFER-FanOut|  146.44|2020-01-02 00:00:00|39be1ea2|e7ec7bdb|\n",
      "|   3997| TRANSFER-Mutual|  439.09|2020-01-03 00:00:00|e2e0d938|afc399a9|\n",
      "|   5518| TRANSFER-FanOut|   361.0|2020-01-04 00:00:00|75c9a805|d7a317f6|\n",
      "|   7340| TRANSFER-Mutual|  768.98|2020-01-06 00:00:00|c14f4989|733a496b|\n",
      "|   9376| TRANSFER-FanOut|   943.4|2020-01-07 00:00:00|576eb672|aa49b0eb|\n",
      "|  10362|TRANSFER-Forward|   668.3|2020-01-08 00:00:00|847a9cf6|b070a6bb|\n",
      "|  10817| TRANSFER-FanOut|  139.84|2020-01-08 00:00:00|12a388ff|586377aa|\n",
      "|  11317| TRANSFER-Mutual|  499.47|2020-01-08 00:00:00|b36f9c84|1b467848|\n",
      "|  11748|TRANSFER-Forward|  357.96|2020-01-09 00:00:00|362e42e0|385afb8b|\n",
      "|  13285|TRANSFER-Forward|   630.9|2020-01-10 00:00:00|572014da|acd60eca|\n",
      "|  14832| TRANSFER-Mutual|  685.07|2020-01-11 00:00:00|5ff2d9a7|31976e38|\n",
      "|  15619| TRANSFER-FanOut|  964.81|2020-01-11 00:00:00|24bf603c|fcf3bbf3|\n",
      "|  16574|TRANSFER-Forward|  919.76|2020-01-12 00:00:00|9a118f8d|ca0967a6|\n",
      "|  18944| TRANSFER-FanOut|  302.26|2020-01-14 00:00:00|65b8a85f|bc0de3c7|\n",
      "|  19204|TRANSFER-Forward|  637.18|2020-01-14 00:00:00|d7a317f6|31db9495|\n",
      "|  19530| TRANSFER-Mutual|  630.43|2020-01-14 00:00:00|95aac0c4|3a63a8fc|\n",
      "|  20382| TRANSFER-Mutual|  374.73|2020-01-15 00:00:00|5411dc34|f388cc0f|\n",
      "+-------+----------------+--------+-------------------+--------+--------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "transactions_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------------+-------+-------+--------+\n",
      "|     src|     dst|tran_timestamp|tran_id|tx_type|base_amt|\n",
      "+--------+--------+--------------+-------+-------+--------+\n",
      "|3aa9646b|1e46e726|        Jan-01|    496|      4|  858.77|\n",
      "|49203bc3|a74d1101|        Jan-01|   1342|      4|  386.86|\n",
      "|616d4505|99af2455|        Jan-02|   1580|      4|  616.43|\n",
      "|39be1ea2|e7ec7bdb|        Jan-02|   2866|      4|  146.44|\n",
      "|e2e0d938|afc399a9|        Jan-03|   3997|      4|  439.09|\n",
      "|75c9a805|d7a317f6|        Jan-04|   5518|      4|   361.0|\n",
      "|c14f4989|733a496b|        Jan-06|   7340|      4|  768.98|\n",
      "|576eb672|aa49b0eb|        Jan-07|   9376|      4|   943.4|\n",
      "|847a9cf6|b070a6bb|        Jan-08|  10362|      4|   668.3|\n",
      "|12a388ff|586377aa|        Jan-08|  10817|      4|  139.84|\n",
      "|b36f9c84|1b467848|        Jan-08|  11317|      4|  499.47|\n",
      "|362e42e0|385afb8b|        Jan-09|  11748|      4|  357.96|\n",
      "|572014da|acd60eca|        Jan-10|  13285|      4|   630.9|\n",
      "|5ff2d9a7|31976e38|        Jan-11|  14832|      4|  685.07|\n",
      "|24bf603c|fcf3bbf3|        Jan-11|  15619|      4|  964.81|\n",
      "|9a118f8d|ca0967a6|        Jan-12|  16574|      4|  919.76|\n",
      "|65b8a85f|bc0de3c7|        Jan-14|  18944|      4|  302.26|\n",
      "|d7a317f6|31db9495|        Jan-14|  19204|      4|  637.18|\n",
      "|95aac0c4|3a63a8fc|        Jan-14|  19530|      4|  630.43|\n",
      "|5411dc34|f388cc0f|        Jan-15|  20382|      4|  374.73|\n",
      "+--------+--------+--------------+-------+-------+--------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "transactions_df = transactions_df.withColumn('tx_type', action_2_code_udf(F.col('tx_type')))\\\n",
    "                                 .withColumn('tran_timestamp', timestamp_2_time_udf(F.col('tran_timestamp')).cast(StringType()))\\\n",
    "                                 .withColumnRenamed(\"orig_acct\",\"source\")\\\n",
    "                                 .withColumnRenamed(\"bene_acct\",\"target\")\\\n",
    "                                 .select(\"src\",\"dst\",\"tran_timestamp\",\"tran_id\",\"tx_type\",\"base_amt\")\n",
    "transactions_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create transactions feature group metadata and save it in to hsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hsfs.feature_group.FeatureGroup object at 0x7fd46e62c6d0>"
     ]
    }
   ],
   "source": [
    "transactions_fg = fs.create_feature_group(name=\"transactions_fg\",\n",
    "                                       version=1,\n",
    "                                       primary_key=[\"tran_id\"],\n",
    "#                                       partition_key=[\"tran_timestamp\"],   \n",
    "                                       description=\"transactions features\",\n",
    "                                       time_travel_format=None,                                        \n",
    "                                       statistics_config=False)\n",
    "transactions_fg.save(transactions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load alert transactions datasets as spark dataframe and perform feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+------+-------+\n",
      "|alert_id|    alert_type|is_sar|tran_id|\n",
      "+--------+--------------+------+-------+\n",
      "|      47|gather_scatter|  true|  11873|\n",
      "|      47|gather_scatter|  true|  11874|\n",
      "|      47|gather_scatter|  true|  11875|\n",
      "|      47|gather_scatter|  true|  13151|\n",
      "|      47|gather_scatter|  true|  23148|\n",
      "|      17|scatter_gather|  true|  23779|\n",
      "|      17|scatter_gather|  true|  23780|\n",
      "|      17|scatter_gather|  true|  26441|\n",
      "|      17|scatter_gather|  true|  26442|\n",
      "|      47|gather_scatter|  true|  28329|\n",
      "|      47|gather_scatter|  true|  31581|\n",
      "|      47|gather_scatter|  true|  34310|\n",
      "|      17|scatter_gather|  true|  34433|\n",
      "|      58|gather_scatter|  true|  36131|\n",
      "|      17|scatter_gather|  true|  36563|\n",
      "|      17|scatter_gather|  true|  41430|\n",
      "|      17|scatter_gather|  true|  42363|\n",
      "|      58|gather_scatter|  true|  42511|\n",
      "|      58|gather_scatter|  true|  44370|\n",
      "|      58|gather_scatter|  true|  46176|\n",
      "+--------+--------------+------+-------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "alert_transactions = spark.read\\\n",
    "             .option(\"inferSchema\", \"true\")\\\n",
    "             .option(\"header\", \"true\")\\\n",
    "             .format(\"csv\")\\\n",
    "             .load(\"hdfs:///Projects/{}/Resources/alert_transactions.csv\".format(hdfs.project_name()))\n",
    "alert_transactions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+------+-------+\n",
      "|alert_id|    alert_type|is_sar|tran_id|\n",
      "+--------+--------------+------+-------+\n",
      "|      47|gather_scatter|  true|  11873|\n",
      "|      47|gather_scatter|  true|  11874|\n",
      "|      47|gather_scatter|  true|  11875|\n",
      "|      47|gather_scatter|  true|  13151|\n",
      "|      47|gather_scatter|  true|  23148|\n",
      "|      17|scatter_gather|  true|  23779|\n",
      "|      17|scatter_gather|  true|  23780|\n",
      "|      17|scatter_gather|  true|  26441|\n",
      "|      17|scatter_gather|  true|  26442|\n",
      "|      47|gather_scatter|  true|  28329|\n",
      "|      47|gather_scatter|  true|  31581|\n",
      "|      47|gather_scatter|  true|  34310|\n",
      "|      17|scatter_gather|  true|  34433|\n",
      "|      58|gather_scatter|  true|  36131|\n",
      "|      17|scatter_gather|  true|  36563|\n",
      "|      17|scatter_gather|  true|  41430|\n",
      "|      17|scatter_gather|  true|  42363|\n",
      "|      58|gather_scatter|  true|  42511|\n",
      "|      58|gather_scatter|  true|  44370|\n",
      "|      58|gather_scatter|  true|  46176|\n",
      "+--------+--------------+------+-------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "alert_transactions = alert_transactions.select(\"alert_id\",\"alert_type\",\"is_sar\",\"tran_id\").orderBy(\"tran_id\")\n",
    "alert_transactions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create alert transactions feature group metadata and perform feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hsfs.feature_group.FeatureGroup object at 0x7fd46e198190>"
     ]
    }
   ],
   "source": [
    "alert_transactions_fg = fs.create_feature_group(name=\"alert_transactions_fg\",\n",
    "                                       version=1,\n",
    "                                       primary_key=[\"tran_id\"],\n",
    "#                                       partition_key=[\"alert_type\"],         \n",
    "                                       description=\"alert transactions\",\n",
    "                                       time_travel_format=None,                                        \n",
    "                                       statistics_config=False)\n",
    "alert_transactions_fg.save(alert_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load party datasets as spark dataframe and ingest into hsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "| partyId|   partyType|\n",
      "+--------+------------+\n",
      "|5628bd6c|Organization|\n",
      "|a1fcba39|Organization|\n",
      "|f56c9501|  Individual|\n",
      "|9969afdd|Organization|\n",
      "|b356eeae|  Individual|\n",
      "|3406706a|Organization|\n",
      "|26c56102|Organization|\n",
      "|e386ebf7|  Individual|\n",
      "|8c094b0d|  Individual|\n",
      "|939235aa|  Individual|\n",
      "|de6bf2a5|Organization|\n",
      "|33a8ff5b|Organization|\n",
      "|a32807a1|  Individual|\n",
      "|2906ef08|Organization|\n",
      "|c2a01b8d|  Individual|\n",
      "|5a99160f|  Individual|\n",
      "|8b9017b8|Organization|\n",
      "|fcf3bbf3|  Individual|\n",
      "|5132aa4d|Organization|\n",
      "|68b90958|  Individual|\n",
      "+--------+------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "party = spark.read\\\n",
    "             .option(\"inferSchema\", \"true\")\\\n",
    "             .option(\"header\", \"true\")\\\n",
    "             .format(\"csv\")\\\n",
    "             .load(\"hdfs:///Projects/{}/Resources/party.csv\".format(hdfs.project_name()))\n",
    "party.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|      id|type|\n",
      "+--------+----+\n",
      "|5628bd6c|   0|\n",
      "|a1fcba39|   0|\n",
      "|f56c9501|   1|\n",
      "|9969afdd|   0|\n",
      "|b356eeae|   1|\n",
      "|3406706a|   0|\n",
      "|26c56102|   0|\n",
      "|e386ebf7|   1|\n",
      "|8c094b0d|   1|\n",
      "|939235aa|   1|\n",
      "|de6bf2a5|   0|\n",
      "|33a8ff5b|   0|\n",
      "|a32807a1|   1|\n",
      "|2906ef08|   0|\n",
      "|c2a01b8d|   1|\n",
      "|5a99160f|   1|\n",
      "|8b9017b8|   0|\n",
      "|fcf3bbf3|   1|\n",
      "|5132aa4d|   0|\n",
      "|68b90958|   1|\n",
      "+--------+----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "party=party.withColumn('partyType', party_2_code_udf(F.col('partyType'))).toDF(\"id\",\"type\")\n",
    "party.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hsfs.feature_group.FeatureGroup object at 0x7fd46e1c7290>"
     ]
    }
   ],
   "source": [
    "party_fg = fs.create_feature_group(name=\"party_fg\",\n",
    "                                       version=1,\n",
    "                                       primary_key=[\"partyId\"],\n",
    "                                       description=\"party fg\",\n",
    "                                       time_travel_format=None,                                        \n",
    "                                       statistics_config=False)\n",
    "party_fg.save(party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
