{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Training Data & Feature views</span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">This is the second part of the quick start series of tutorials about Hopsworks Feature Store. This notebook explains how to read from a feature group and create training dataset within the feature store</span>\n",
    "\n",
    "## **üóíÔ∏è In this notebook we will see how to create a training dataset from the feature groups:** \n",
    "1. **Select the features** we want to train our model on,\n",
    "2. **How the features should be preprocessed,**\n",
    "3. **Create a dataset split** for training and validation data.\n",
    "\n",
    "![tutorial-flow](images/02_training-dataset.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a connection to hsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "from hops import hdfs\n",
    "# Create a connection\n",
    "connection = hsfs.connection()\n",
    "# Get the feature store handle for the project's feature store\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üî™ Feature Selection </span>\n",
    "\n",
    "### We start by selecting all the features we want to include for model training/inference.\n",
    "\n",
    "In the next notebook we are going to train [gan for anomaly detection](https://arxiv.org/pdf/1905.11034.pdf). Durring training step  we will provide only features of accounts that have never been reported for money laundering behaviour.  But we will disclose previously reported accounts to the model only in evaluation step.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "### Retrieve alert nodes feature group from hsfs\n",
    "transactions_monthly_fg = fs.get_feature_group(\"transactions_monthly_fg\", 1)\n",
    "graph_embeddings_fg = fs.get_feature_group(\"graph_embeddings_fg\", 1) \n",
    "party_fg = fs.get_feature_group(\"party_fg\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For training we will include exlude all known SAR customers and include only non SAR ones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "non_sar_transac_query = party_fg.select_all().join(transactions_monthly_fg.select_all()).join(graph_embeddings_fg.select_all()).filter(party_fg.is_sar == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-07 12:45:00,718 INFO: USE `aml_demo_featurestore`\n",
      "2022-06-07 12:45:01,547 INFO: WITH right_fg0 AS (SELECT *\n",
      "FROM (SELECT `fg2`.`id` `id`, `fg2`.`type` `type`, `fg2`.`tran_timestamp` `tran_timestamp`, `fg2`.`is_sar` `is_sar`, `fg2`.`id` `join_pk_id`, `fg2`.`tran_timestamp` `join_evt_tran_timestamp`, `fg0`.`monthly_in_count` `monthly_in_count`, `fg0`.`monthly_in_total_amount` `monthly_in_total_amount`, `fg0`.`monthly_in_mean_amount` `monthly_in_mean_amount`, `fg0`.`monthly_in_std_amount` `monthly_in_std_amount`, `fg0`.`monthly_out_count` `monthly_out_count`, `fg0`.`monthly_out_total_amount` `monthly_out_total_amount`, `fg0`.`monthly_out_mean_amount` `monthly_out_mean_amount`, `fg0`.`monthly_out_std_amount` `monthly_out_std_amount`, RANK() OVER (PARTITION BY `fg0`.`id`, `fg2`.`tran_timestamp` ORDER BY `fg0`.`tran_timestamp` DESC) pit_rank_hopsworks\n",
      "FROM `aml_demo_featurestore`.`party_fg_1` `fg2`\n",
      "INNER JOIN `aml_demo_featurestore`.`transactions_monthly_fg_1` `fg0` ON `fg2`.`id` = `fg0`.`id` AND `fg2`.`tran_timestamp` >= `fg0`.`tran_timestamp`\n",
      "WHERE `fg2`.`is_sar` = 0) NA\n",
      "WHERE `pit_rank_hopsworks` = 1), right_fg1 AS (SELECT *\n",
      "FROM (SELECT `fg2`.`id` `id`, `fg2`.`type` `type`, `fg2`.`tran_timestamp` `tran_timestamp`, `fg2`.`is_sar` `is_sar`, `fg2`.`id` `join_pk_id`, `fg2`.`tran_timestamp` `join_evt_tran_timestamp`, `fg1`.`graph_embeddings` `graph_embeddings`, RANK() OVER (PARTITION BY `fg1`.`id`, `fg2`.`tran_timestamp` ORDER BY `fg1`.`tran_timestamp` DESC) pit_rank_hopsworks\n",
      "FROM `aml_demo_featurestore`.`party_fg_1` `fg2`\n",
      "INNER JOIN `aml_demo_featurestore`.`graph_embeddings_fg_1` `fg1` ON `fg2`.`id` = `fg1`.`id` AND `fg2`.`tran_timestamp` >= `fg1`.`tran_timestamp`\n",
      "WHERE `fg2`.`is_sar` = 0) NA\n",
      "WHERE `pit_rank_hopsworks` = 1) (SELECT `right_fg0`.`id` `id`, `right_fg0`.`type` `type`, `right_fg0`.`tran_timestamp` `tran_timestamp`, `right_fg0`.`is_sar` `is_sar`, `right_fg0`.`monthly_in_count` `monthly_in_count`, `right_fg0`.`monthly_in_total_amount` `monthly_in_total_amount`, `right_fg0`.`monthly_in_mean_amount` `monthly_in_mean_amount`, `right_fg0`.`monthly_in_std_amount` `monthly_in_std_amount`, `right_fg0`.`monthly_out_count` `monthly_out_count`, `right_fg0`.`monthly_out_total_amount` `monthly_out_total_amount`, `right_fg0`.`monthly_out_mean_amount` `monthly_out_mean_amount`, `right_fg0`.`monthly_out_std_amount` `monthly_out_std_amount`, `right_fg1`.`graph_embeddings` `graph_embeddings`\n",
      "FROM right_fg0\n",
      "INNER JOIN right_fg1 ON `right_fg0`.`join_pk_id` = `right_fg1`.`join_pk_id` AND `right_fg0`.`join_evt_tran_timestamp` = `right_fg1`.`join_evt_tran_timestamp`)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>tran_timestamp</th>\n",
       "      <th>is_sar</th>\n",
       "      <th>monthly_in_count</th>\n",
       "      <th>monthly_in_total_amount</th>\n",
       "      <th>monthly_in_mean_amount</th>\n",
       "      <th>monthly_in_std_amount</th>\n",
       "      <th>monthly_out_count</th>\n",
       "      <th>monthly_out_total_amount</th>\n",
       "      <th>monthly_out_mean_amount</th>\n",
       "      <th>monthly_out_std_amount</th>\n",
       "      <th>graph_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00498ec2</td>\n",
       "      <td>0</td>\n",
       "      <td>1639958400000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>872.57</td>\n",
       "      <td>436.285000</td>\n",
       "      <td>287.276272</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3423.55</td>\n",
       "      <td>570.591667</td>\n",
       "      <td>313.650815</td>\n",
       "      <td>[-7.408532E-4,-5.044542E-4,3.7164874,5.2371387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>008e1390</td>\n",
       "      <td>0</td>\n",
       "      <td>1639958400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2721.74</td>\n",
       "      <td>544.348000</td>\n",
       "      <td>418.977750</td>\n",
       "      <td>[46.100166,49.332905,-0.0,-0.0,50.410557,35.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00a73023</td>\n",
       "      <td>1</td>\n",
       "      <td>1639958400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>838.77</td>\n",
       "      <td>838.770000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2761.11</td>\n",
       "      <td>690.277500</td>\n",
       "      <td>203.299050</td>\n",
       "      <td>[-7.4465707E-4,-5.0696253E-4,3.7152529,5.23590...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00aee0c0</td>\n",
       "      <td>1</td>\n",
       "      <td>1639958400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>527.89</td>\n",
       "      <td>527.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1453.10</td>\n",
       "      <td>726.550000</td>\n",
       "      <td>19.657569</td>\n",
       "      <td>[-7.5425365E-4,-5.139923E-4,3.7118905,5.232578...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b46048</td>\n",
       "      <td>1</td>\n",
       "      <td>1639958400000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1746.53</td>\n",
       "      <td>582.176667</td>\n",
       "      <td>286.101247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[46.10027,49.333035,-0.0,-0.0,50.410652,35.412...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  type  tran_timestamp  is_sar  monthly_in_count  \\\n",
       "0  00498ec2     0   1639958400000       0               2.0   \n",
       "1  008e1390     0   1639958400000       0               0.0   \n",
       "2  00a73023     1   1639958400000       0               1.0   \n",
       "3  00aee0c0     1   1639958400000       0               1.0   \n",
       "4  00b46048     1   1639958400000       0               3.0   \n",
       "\n",
       "   monthly_in_total_amount  monthly_in_mean_amount  monthly_in_std_amount  \\\n",
       "0                   872.57              436.285000             287.276272   \n",
       "1                     0.00                0.000000               0.000000   \n",
       "2                   838.77              838.770000               0.000000   \n",
       "3                   527.89              527.890000               0.000000   \n",
       "4                  1746.53              582.176667             286.101247   \n",
       "\n",
       "   monthly_out_count  monthly_out_total_amount  monthly_out_mean_amount  \\\n",
       "0                6.0                   3423.55               570.591667   \n",
       "1                5.0                   2721.74               544.348000   \n",
       "2                4.0                   2761.11               690.277500   \n",
       "3                2.0                   1453.10               726.550000   \n",
       "4                0.0                      0.00                 0.000000   \n",
       "\n",
       "   monthly_out_std_amount                                   graph_embeddings  \n",
       "0              313.650815  [-7.408532E-4,-5.044542E-4,3.7164874,5.2371387...  \n",
       "1              418.977750  [46.100166,49.332905,-0.0,-0.0,50.410557,35.41...  \n",
       "2              203.299050  [-7.4465707E-4,-5.0696253E-4,3.7152529,5.23590...  \n",
       "3               19.657569  [-7.5425365E-4,-5.139923E-4,3.7118905,5.232578...  \n",
       "4                0.000000  [46.10027,49.333035,-0.0,-0.0,50.410652,35.412...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_sar_transac_query.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For testing and evaluation we will include known SAR nodes to measure anomaly score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "sar_transac_query = party_fg.select_all().join(transactions_monthly_fg.select_all()).join(graph_embeddings_fg.select_all()).filter(party_fg.is_sar == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-07 12:51:04,284 INFO: USE `aml_demo_featurestore`\n",
      "2022-06-07 12:51:05,133 INFO: WITH right_fg0 AS (SELECT *\n",
      "FROM (SELECT `fg2`.`id` `id`, `fg2`.`type` `type`, `fg2`.`tran_timestamp` `tran_timestamp`, `fg2`.`is_sar` `is_sar`, `fg2`.`id` `join_pk_id`, `fg2`.`tran_timestamp` `join_evt_tran_timestamp`, `fg0`.`monthly_in_count` `monthly_in_count`, `fg0`.`monthly_in_total_amount` `monthly_in_total_amount`, `fg0`.`monthly_in_mean_amount` `monthly_in_mean_amount`, `fg0`.`monthly_in_std_amount` `monthly_in_std_amount`, `fg0`.`monthly_out_count` `monthly_out_count`, `fg0`.`monthly_out_total_amount` `monthly_out_total_amount`, `fg0`.`monthly_out_mean_amount` `monthly_out_mean_amount`, `fg0`.`monthly_out_std_amount` `monthly_out_std_amount`, RANK() OVER (PARTITION BY `fg0`.`id`, `fg2`.`tran_timestamp` ORDER BY `fg0`.`tran_timestamp` DESC) pit_rank_hopsworks\n",
      "FROM `aml_demo_featurestore`.`party_fg_1` `fg2`\n",
      "INNER JOIN `aml_demo_featurestore`.`transactions_monthly_fg_1` `fg0` ON `fg2`.`id` = `fg0`.`id` AND `fg2`.`tran_timestamp` >= `fg0`.`tran_timestamp`\n",
      "WHERE `fg2`.`is_sar` = 1) NA\n",
      "WHERE `pit_rank_hopsworks` = 1), right_fg1 AS (SELECT *\n",
      "FROM (SELECT `fg2`.`id` `id`, `fg2`.`type` `type`, `fg2`.`tran_timestamp` `tran_timestamp`, `fg2`.`is_sar` `is_sar`, `fg2`.`id` `join_pk_id`, `fg2`.`tran_timestamp` `join_evt_tran_timestamp`, `fg1`.`graph_embeddings` `graph_embeddings`, RANK() OVER (PARTITION BY `fg1`.`id`, `fg2`.`tran_timestamp` ORDER BY `fg1`.`tran_timestamp` DESC) pit_rank_hopsworks\n",
      "FROM `aml_demo_featurestore`.`party_fg_1` `fg2`\n",
      "INNER JOIN `aml_demo_featurestore`.`graph_embeddings_fg_1` `fg1` ON `fg2`.`id` = `fg1`.`id` AND `fg2`.`tran_timestamp` >= `fg1`.`tran_timestamp`\n",
      "WHERE `fg2`.`is_sar` = 1) NA\n",
      "WHERE `pit_rank_hopsworks` = 1) (SELECT `right_fg0`.`id` `id`, `right_fg0`.`type` `type`, `right_fg0`.`tran_timestamp` `tran_timestamp`, `right_fg0`.`is_sar` `is_sar`, `right_fg0`.`monthly_in_count` `monthly_in_count`, `right_fg0`.`monthly_in_total_amount` `monthly_in_total_amount`, `right_fg0`.`monthly_in_mean_amount` `monthly_in_mean_amount`, `right_fg0`.`monthly_in_std_amount` `monthly_in_std_amount`, `right_fg0`.`monthly_out_count` `monthly_out_count`, `right_fg0`.`monthly_out_total_amount` `monthly_out_total_amount`, `right_fg0`.`monthly_out_mean_amount` `monthly_out_mean_amount`, `right_fg0`.`monthly_out_std_amount` `monthly_out_std_amount`, `right_fg1`.`graph_embeddings` `graph_embeddings`\n",
      "FROM right_fg0\n",
      "INNER JOIN right_fg1 ON `right_fg0`.`join_pk_id` = `right_fg1`.`join_pk_id` AND `right_fg0`.`join_evt_tran_timestamp` = `right_fg1`.`join_evt_tran_timestamp`)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>tran_timestamp</th>\n",
       "      <th>is_sar</th>\n",
       "      <th>monthly_in_count</th>\n",
       "      <th>monthly_in_total_amount</th>\n",
       "      <th>monthly_in_mean_amount</th>\n",
       "      <th>monthly_in_std_amount</th>\n",
       "      <th>monthly_out_count</th>\n",
       "      <th>monthly_out_total_amount</th>\n",
       "      <th>monthly_out_mean_amount</th>\n",
       "      <th>monthly_out_std_amount</th>\n",
       "      <th>graph_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02e4febf</td>\n",
       "      <td>0</td>\n",
       "      <td>1638230400000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3002.24</td>\n",
       "      <td>1501.120</td>\n",
       "      <td>1409.999206</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2738.13</td>\n",
       "      <td>684.5325</td>\n",
       "      <td>218.936394</td>\n",
       "      <td>[-7.4465707E-4,-5.0696253E-4,3.715253,5.235906...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>053485ef</td>\n",
       "      <td>0</td>\n",
       "      <td>1630368000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18065.11</td>\n",
       "      <td>2580.730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1457.97</td>\n",
       "      <td>485.9900</td>\n",
       "      <td>222.568563</td>\n",
       "      <td>[-0.0,-0.0,23.231258,-0.0,20.905884,-0.0,19.88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>071ef7d3</td>\n",
       "      <td>1</td>\n",
       "      <td>1596153600000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2955.89</td>\n",
       "      <td>1477.945</td>\n",
       "      <td>1438.743097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.0,17.563562,21.542643,23.562359,24.05239,2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>085b2c81</td>\n",
       "      <td>0</td>\n",
       "      <td>1635638400000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2814.40</td>\n",
       "      <td>1407.200</td>\n",
       "      <td>1722.229276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.027679602,4.8106894,4.7229276,-3.5944706E-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08c3287c</td>\n",
       "      <td>1</td>\n",
       "      <td>1632960000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3140.78</td>\n",
       "      <td>628.156</td>\n",
       "      <td>256.421333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2651.84</td>\n",
       "      <td>2651.8400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.0,43.488667,45.72255,-0.0,40.119152,-0.0,-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  type  tran_timestamp  is_sar  monthly_in_count  \\\n",
       "0  02e4febf     0   1638230400000       1               2.0   \n",
       "1  053485ef     0   1630368000000       1               7.0   \n",
       "2  071ef7d3     1   1596153600000       1               2.0   \n",
       "3  085b2c81     0   1635638400000       1               2.0   \n",
       "4  08c3287c     1   1632960000000       1               5.0   \n",
       "\n",
       "   monthly_in_total_amount  monthly_in_mean_amount  monthly_in_std_amount  \\\n",
       "0                  3002.24                1501.120            1409.999206   \n",
       "1                 18065.11                2580.730               0.000000   \n",
       "2                  2955.89                1477.945            1438.743097   \n",
       "3                  2814.40                1407.200            1722.229276   \n",
       "4                  3140.78                 628.156             256.421333   \n",
       "\n",
       "   monthly_out_count  monthly_out_total_amount  monthly_out_mean_amount  \\\n",
       "0                4.0                   2738.13                 684.5325   \n",
       "1                3.0                   1457.97                 485.9900   \n",
       "2                0.0                      0.00                   0.0000   \n",
       "3                0.0                      0.00                   0.0000   \n",
       "4                1.0                   2651.84                2651.8400   \n",
       "\n",
       "   monthly_out_std_amount                                   graph_embeddings  \n",
       "0              218.936394  [-7.4465707E-4,-5.0696253E-4,3.715253,5.235906...  \n",
       "1              222.568563  [-0.0,-0.0,23.231258,-0.0,20.905884,-0.0,19.88...  \n",
       "2                0.000000  [-0.0,17.563562,21.542643,23.562359,24.05239,2...  \n",
       "3                0.000000  [-0.027679602,4.8106894,4.7229276,-3.5944706E-...  \n",
       "4                0.000000  [-0.0,43.488667,45.72255,-0.0,40.119152,-0.0,-...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_transac_query.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation </span>\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "In order to create a Feature View we may use `fs.create_feature_view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "Training dataset is created using `fs.create_training_dataset()` method.\n",
    "\n",
    "**From feature view APIs we can also create training datasts based on even time filters specifing `start_time` and `end_time`** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ü™ù Training Dataset retreival </span>\n",
    "\n",
    "To retrieve training data from storage (already materialised) or from feature groups direcly we can use `get_training_dataset_splits` or `get_training_dataset` methods. If version is not provided or provided version has not already existed, it creates a new version of training data according to given arguments and returns a dataframe. If version is provided and has already existed, it reads training data from storage or feature groups and returns a dataframe. If split is provided, it reads the specific split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserWarning: Training dataset splits were defined but no `train_split` (the name of the split that is going to be used for training) was provided. Setting this property to `train`. The statistics of this split will be used for transformation functions."
     ]
    }
   ],
   "source": [
    "non_sar_td = fs.create_training_dataset(name=\"gan_non_sar_training_df\",\n",
    "                                       version=1,\n",
    "                                       data_format=\"tfrecord\",\n",
    "                                       label=[\"is_sar\"], \n",
    "                                       statistics_config={\"enabled\": False, \"histograms\": False, \"correlations\": False, \"exact_uniqueness\": False}, \n",
    "                                       splits={'train': 0.8, 'test': 0.2},\n",
    "                                       coalesce=True,\n",
    "                                       description=\"non sar dataset for gan training\")\n",
    "non_sar_td.save(non_sar_emb_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For testing and evaluation we will include known SAR nodes to measure anomaly score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_sar_td = fs.get_training_dataset(\"gan_non_sar_training_df\", 1)\n",
    "non_sar_test_df = non_sar_td.read(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_emb_query = node_embeddings_fg.select([\"embedding\"])\\\n",
    "                                  .join(alert_nodes_fg.select([\"is_sar\"])\\\n",
    "                                  .filter(alert_nodes_fg.is_sar == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|           embedding|is_sar|\n",
      "+--------------------+------+\n",
      "|[-0.9998507499694...|     0|\n",
      "|[-0.9986557960510...|     0|\n",
      "|[-0.9984421730041...|     0|\n",
      "|[-0.9970214366912...|     0|\n",
      "|[-0.9947502613067...|     0|\n",
      "|[-0.9934816360473...|     0|\n",
      "|[-0.9908211231231...|     0|\n",
      "|[-0.9882340431213...|     0|\n",
      "|[-0.9830579757690...|     0|\n",
      "|[-0.9823658466339...|     0|\n",
      "|[-0.9815602302551...|     0|\n",
      "|[-0.9814951419830...|     0|\n",
      "|[-0.9812114238739...|     0|\n",
      "|[-0.9809970855712...|     0|\n",
      "|[-0.9808425903320...|     0|\n",
      "|[-0.9780859947204...|     0|\n",
      "|[-0.9746136665344...|     0|\n",
      "|[-0.9715352058410...|     0|\n",
      "|[-0.9711296558380...|     0|\n",
      "|[-0.9682199954986...|     0|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "sar_df = sar_emb_query.read()\n",
    "sar_df = sar_df.select(*non_sar_test_df.columns)\n",
    "eval_df = non_sar_test_df.union(sar_df)\n",
    "eval_df.cache()\n",
    "eval_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1267"
     ]
    }
   ],
   "source": [
    "non_sar_test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816"
     ]
    }
   ],
   "source": [
    "sar_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2083"
     ]
    }
   ],
   "source": [
    "eval_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_eval_ds = fs.create_training_dataset(name=\"gan_eval_df\",\n",
    "                                       version=1,\n",
    "                                       data_format=\"tfrecord\",\n",
    "                                       label=[\"is_sar\"], \n",
    "                                       statistics_config={\"enabled\": False, \"histograms\": False, \"correlations\": False, \"exact_uniqueness\": False}, \n",
    "                                       coalesce = True,\n",
    "                                       description=\"evaluation dataset for gan training\")\n",
    "gan_eval_ds.save(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}