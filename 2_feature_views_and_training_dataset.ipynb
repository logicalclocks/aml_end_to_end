{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Training Data & Feature views</span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">This is the second part of the quick start series of tutorials about Hopsworks Feature Store. This notebook explains how to read from a feature group and create training dataset within the feature store</span>\n",
    "\n",
    "## **üóíÔ∏è In this notebook we will see how to create a training dataset from the feature groups:** \n",
    "1. **Select the features** we want to train our model on,\n",
    "2. **How the features should be preprocessed,**\n",
    "3. **Create a dataset split** for training and validation data.\n",
    "\n",
    "![tutorial-flow](images/02_training-dataset.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a connection to hsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "from hops import hdfs\n",
    "# Create a connection\n",
    "connection = hsfs.connection()\n",
    "# Get the feature store handle for the project's feature store\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üî™ Feature Selection </span>\n",
    "\n",
    "### We start by selecting all the features we want to include for model training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "### Retrieve alert nodes feature group from hsfs\n",
    "transactions_monthly_fg = fs.get_feature_group(\"transactions_monthly_fg\", 1)\n",
    "graph_embeddings_fg = fs.get_feature_group(\"graph_embeddings_fg\", 1) \n",
    "party_fg = fs.get_feature_group(\"party_fg\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AML model query \n",
    "aml_model_query = party_fg.select([\"type\", \"is_sar\"])\\\n",
    "                            .join(transactions_monthly_fg.select([\"monthly_in_count\", \n",
    "                                                                  \"monthly_in_total_amount\", \n",
    "                                                                  \"monthly_in_mean_amount\", \n",
    "                                                                  \"monthly_in_std_amount\", \n",
    "                                                                  \"monthly_out_count\", \n",
    "                                                                  \"monthly_out_total_amount\", \n",
    "                                                                  \"monthly_out_mean_amount\", \n",
    "                                                                  \"monthly_out_std_amount\"]))\\\n",
    "                            .join(graph_embeddings_fg.select([\"graph_embeddings\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train [gan for anomaly detection](https://arxiv.org/pdf/1905.11034.pdf). Durring training step  we will provide only features of accounts that have never been reported for suspicios activity.  We will disclose previously reported accounts to the model only in evaluation step.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_sar_transac_query = aml_model_query.filter(party_fg.is_sar == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-07 16:24:33,225 INFO: USE `aml_demo_featurestore`\n",
      "2022-06-07 16:24:33,979 INFO: WITH right_fg0 AS (SELECT *\n",
      "FROM (SELECT `fg2`.`type` `type`, `fg2`.`is_sar` `is_sar`, `fg2`.`id` `join_pk_id`, `fg2`.`tran_timestamp` `join_evt_tran_timestamp`, `fg0`.`monthly_in_count` `monthly_in_count`, `fg0`.`monthly_in_total_amount` `monthly_in_total_amount`, `fg0`.`monthly_in_mean_amount` `monthly_in_mean_amount`, `fg0`.`monthly_in_std_amount` `monthly_in_std_amount`, `fg0`.`monthly_out_count` `monthly_out_count`, `fg0`.`monthly_out_total_amount` `monthly_out_total_amount`, `fg0`.`monthly_out_mean_amount` `monthly_out_mean_amount`, `fg0`.`monthly_out_std_amount` `monthly_out_std_amount`, RANK() OVER (PARTITION BY `fg0`.`id`, `fg2`.`tran_timestamp` ORDER BY `fg0`.`tran_timestamp` DESC) pit_rank_hopsworks\n",
      "FROM `aml_demo_featurestore`.`party_fg_1` `fg2`\n",
      "INNER JOIN `aml_demo_featurestore`.`transactions_monthly_fg_1` `fg0` ON `fg2`.`id` = `fg0`.`id` AND `fg2`.`tran_timestamp` >= `fg0`.`tran_timestamp`\n",
      "WHERE `fg2`.`is_sar` = 0) NA\n",
      "WHERE `pit_rank_hopsworks` = 1), right_fg1 AS (SELECT *\n",
      "FROM (SELECT `fg2`.`type` `type`, `fg2`.`is_sar` `is_sar`, `fg2`.`id` `join_pk_id`, `fg2`.`tran_timestamp` `join_evt_tran_timestamp`, `fg1`.`graph_embeddings` `graph_embeddings`, RANK() OVER (PARTITION BY `fg1`.`id`, `fg2`.`tran_timestamp` ORDER BY `fg1`.`tran_timestamp` DESC) pit_rank_hopsworks\n",
      "FROM `aml_demo_featurestore`.`party_fg_1` `fg2`\n",
      "INNER JOIN `aml_demo_featurestore`.`graph_embeddings_fg_1` `fg1` ON `fg2`.`id` = `fg1`.`id` AND `fg2`.`tran_timestamp` >= `fg1`.`tran_timestamp`\n",
      "WHERE `fg2`.`is_sar` = 0) NA\n",
      "WHERE `pit_rank_hopsworks` = 1) (SELECT `right_fg0`.`type` `type`, `right_fg0`.`is_sar` `is_sar`, `right_fg0`.`monthly_in_count` `monthly_in_count`, `right_fg0`.`monthly_in_total_amount` `monthly_in_total_amount`, `right_fg0`.`monthly_in_mean_amount` `monthly_in_mean_amount`, `right_fg0`.`monthly_in_std_amount` `monthly_in_std_amount`, `right_fg0`.`monthly_out_count` `monthly_out_count`, `right_fg0`.`monthly_out_total_amount` `monthly_out_total_amount`, `right_fg0`.`monthly_out_mean_amount` `monthly_out_mean_amount`, `right_fg0`.`monthly_out_std_amount` `monthly_out_std_amount`, `right_fg1`.`graph_embeddings` `graph_embeddings`\n",
      "FROM right_fg0\n",
      "INNER JOIN right_fg1 ON `right_fg0`.`join_pk_id` = `right_fg1`.`join_pk_id` AND `right_fg0`.`join_evt_tran_timestamp` = `right_fg1`.`join_evt_tran_timestamp`)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>is_sar</th>\n",
       "      <th>monthly_in_count</th>\n",
       "      <th>monthly_in_total_amount</th>\n",
       "      <th>monthly_in_mean_amount</th>\n",
       "      <th>monthly_in_std_amount</th>\n",
       "      <th>monthly_out_count</th>\n",
       "      <th>monthly_out_total_amount</th>\n",
       "      <th>monthly_out_mean_amount</th>\n",
       "      <th>monthly_out_std_amount</th>\n",
       "      <th>graph_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>872.57</td>\n",
       "      <td>436.285000</td>\n",
       "      <td>287.276272</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3423.55</td>\n",
       "      <td>570.591667</td>\n",
       "      <td>313.650815</td>\n",
       "      <td>[-7.408532E-4,-5.044542E-4,3.7164874,5.2371387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2721.74</td>\n",
       "      <td>544.348000</td>\n",
       "      <td>418.977750</td>\n",
       "      <td>[46.100166,49.332905,-0.0,-0.0,50.410557,35.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>838.77</td>\n",
       "      <td>838.770000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2761.11</td>\n",
       "      <td>690.277500</td>\n",
       "      <td>203.299050</td>\n",
       "      <td>[-7.4465707E-4,-5.0696253E-4,3.7152529,5.23590...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>527.89</td>\n",
       "      <td>527.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1453.10</td>\n",
       "      <td>726.550000</td>\n",
       "      <td>19.657569</td>\n",
       "      <td>[-7.5425365E-4,-5.139923E-4,3.7118905,5.232578...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1746.53</td>\n",
       "      <td>582.176667</td>\n",
       "      <td>286.101247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[46.10027,49.333035,-0.0,-0.0,50.410652,35.412...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  is_sar  monthly_in_count  monthly_in_total_amount  \\\n",
       "0     0       0               2.0                   872.57   \n",
       "1     0       0               0.0                     0.00   \n",
       "2     1       0               1.0                   838.77   \n",
       "3     1       0               1.0                   527.89   \n",
       "4     1       0               3.0                  1746.53   \n",
       "\n",
       "   monthly_in_mean_amount  monthly_in_std_amount  monthly_out_count  \\\n",
       "0              436.285000             287.276272                6.0   \n",
       "1                0.000000               0.000000                5.0   \n",
       "2              838.770000               0.000000                4.0   \n",
       "3              527.890000               0.000000                2.0   \n",
       "4              582.176667             286.101247                0.0   \n",
       "\n",
       "   monthly_out_total_amount  monthly_out_mean_amount  monthly_out_std_amount  \\\n",
       "0                   3423.55               570.591667              313.650815   \n",
       "1                   2721.74               544.348000              418.977750   \n",
       "2                   2761.11               690.277500              203.299050   \n",
       "3                   1453.10               726.550000               19.657569   \n",
       "4                      0.00                 0.000000                0.000000   \n",
       "\n",
       "                                    graph_embeddings  \n",
       "0  [-7.408532E-4,-5.044542E-4,3.7164874,5.2371387...  \n",
       "1  [46.100166,49.332905,-0.0,-0.0,50.410557,35.41...  \n",
       "2  [-7.4465707E-4,-5.0696253E-4,3.7152529,5.23590...  \n",
       "3  [-7.5425365E-4,-5.139923E-4,3.7118905,5.232578...  \n",
       "4  [46.10027,49.333035,-0.0,-0.0,50.410652,35.412...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_sar_transac_query.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing and evaluation we will include known SAR nodes to measure anomaly score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "sar_transac_query = party_fg.select_all().join(transactions_monthly_fg.select_all()).join(graph_embeddings_fg.select_all()).filter(party_fg.is_sar == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-07 16:26:00,269 INFO: USE `aml_demo_featurestore`\n",
      "2022-06-07 16:26:01,078 INFO: WITH right_fg0 AS (SELECT *\n",
      "FROM (SELECT `fg2`.`id` `id`, `fg2`.`type` `type`, `fg2`.`tran_timestamp` `tran_timestamp`, `fg2`.`is_sar` `is_sar`, `fg2`.`id` `join_pk_id`, `fg2`.`tran_timestamp` `join_evt_tran_timestamp`, `fg0`.`monthly_in_count` `monthly_in_count`, `fg0`.`monthly_in_total_amount` `monthly_in_total_amount`, `fg0`.`monthly_in_mean_amount` `monthly_in_mean_amount`, `fg0`.`monthly_in_std_amount` `monthly_in_std_amount`, `fg0`.`monthly_out_count` `monthly_out_count`, `fg0`.`monthly_out_total_amount` `monthly_out_total_amount`, `fg0`.`monthly_out_mean_amount` `monthly_out_mean_amount`, `fg0`.`monthly_out_std_amount` `monthly_out_std_amount`, RANK() OVER (PARTITION BY `fg0`.`id`, `fg2`.`tran_timestamp` ORDER BY `fg0`.`tran_timestamp` DESC) pit_rank_hopsworks\n",
      "FROM `aml_demo_featurestore`.`party_fg_1` `fg2`\n",
      "INNER JOIN `aml_demo_featurestore`.`transactions_monthly_fg_1` `fg0` ON `fg2`.`id` = `fg0`.`id` AND `fg2`.`tran_timestamp` >= `fg0`.`tran_timestamp`\n",
      "WHERE `fg2`.`is_sar` = 1) NA\n",
      "WHERE `pit_rank_hopsworks` = 1), right_fg1 AS (SELECT *\n",
      "FROM (SELECT `fg2`.`id` `id`, `fg2`.`type` `type`, `fg2`.`tran_timestamp` `tran_timestamp`, `fg2`.`is_sar` `is_sar`, `fg2`.`id` `join_pk_id`, `fg2`.`tran_timestamp` `join_evt_tran_timestamp`, `fg1`.`graph_embeddings` `graph_embeddings`, RANK() OVER (PARTITION BY `fg1`.`id`, `fg2`.`tran_timestamp` ORDER BY `fg1`.`tran_timestamp` DESC) pit_rank_hopsworks\n",
      "FROM `aml_demo_featurestore`.`party_fg_1` `fg2`\n",
      "INNER JOIN `aml_demo_featurestore`.`graph_embeddings_fg_1` `fg1` ON `fg2`.`id` = `fg1`.`id` AND `fg2`.`tran_timestamp` >= `fg1`.`tran_timestamp`\n",
      "WHERE `fg2`.`is_sar` = 1) NA\n",
      "WHERE `pit_rank_hopsworks` = 1) (SELECT `right_fg0`.`id` `id`, `right_fg0`.`type` `type`, `right_fg0`.`tran_timestamp` `tran_timestamp`, `right_fg0`.`is_sar` `is_sar`, `right_fg0`.`monthly_in_count` `monthly_in_count`, `right_fg0`.`monthly_in_total_amount` `monthly_in_total_amount`, `right_fg0`.`monthly_in_mean_amount` `monthly_in_mean_amount`, `right_fg0`.`monthly_in_std_amount` `monthly_in_std_amount`, `right_fg0`.`monthly_out_count` `monthly_out_count`, `right_fg0`.`monthly_out_total_amount` `monthly_out_total_amount`, `right_fg0`.`monthly_out_mean_amount` `monthly_out_mean_amount`, `right_fg0`.`monthly_out_std_amount` `monthly_out_std_amount`, `right_fg1`.`graph_embeddings` `graph_embeddings`\n",
      "FROM right_fg0\n",
      "INNER JOIN right_fg1 ON `right_fg0`.`join_pk_id` = `right_fg1`.`join_pk_id` AND `right_fg0`.`join_evt_tran_timestamp` = `right_fg1`.`join_evt_tran_timestamp`)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>tran_timestamp</th>\n",
       "      <th>is_sar</th>\n",
       "      <th>monthly_in_count</th>\n",
       "      <th>monthly_in_total_amount</th>\n",
       "      <th>monthly_in_mean_amount</th>\n",
       "      <th>monthly_in_std_amount</th>\n",
       "      <th>monthly_out_count</th>\n",
       "      <th>monthly_out_total_amount</th>\n",
       "      <th>monthly_out_mean_amount</th>\n",
       "      <th>monthly_out_std_amount</th>\n",
       "      <th>graph_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02e4febf</td>\n",
       "      <td>0</td>\n",
       "      <td>1638230400000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3002.24</td>\n",
       "      <td>1501.120</td>\n",
       "      <td>1409.999206</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2738.13</td>\n",
       "      <td>684.5325</td>\n",
       "      <td>218.936394</td>\n",
       "      <td>[-7.4465707E-4,-5.0696253E-4,3.715253,5.235906...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>053485ef</td>\n",
       "      <td>0</td>\n",
       "      <td>1630368000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18065.11</td>\n",
       "      <td>2580.730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1457.97</td>\n",
       "      <td>485.9900</td>\n",
       "      <td>222.568563</td>\n",
       "      <td>[-0.0,-0.0,23.231258,-0.0,20.905884,-0.0,19.88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>071ef7d3</td>\n",
       "      <td>1</td>\n",
       "      <td>1596153600000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2955.89</td>\n",
       "      <td>1477.945</td>\n",
       "      <td>1438.743097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.0,17.563562,21.542643,23.562359,24.05239,2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>085b2c81</td>\n",
       "      <td>0</td>\n",
       "      <td>1635638400000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2814.40</td>\n",
       "      <td>1407.200</td>\n",
       "      <td>1722.229276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.027679602,4.8106894,4.7229276,-3.5944706E-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08c3287c</td>\n",
       "      <td>1</td>\n",
       "      <td>1632960000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3140.78</td>\n",
       "      <td>628.156</td>\n",
       "      <td>256.421333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2651.84</td>\n",
       "      <td>2651.8400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.0,43.488667,45.72255,-0.0,40.119152,-0.0,-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  type  tran_timestamp  is_sar  monthly_in_count  \\\n",
       "0  02e4febf     0   1638230400000       1               2.0   \n",
       "1  053485ef     0   1630368000000       1               7.0   \n",
       "2  071ef7d3     1   1596153600000       1               2.0   \n",
       "3  085b2c81     0   1635638400000       1               2.0   \n",
       "4  08c3287c     1   1632960000000       1               5.0   \n",
       "\n",
       "   monthly_in_total_amount  monthly_in_mean_amount  monthly_in_std_amount  \\\n",
       "0                  3002.24                1501.120            1409.999206   \n",
       "1                 18065.11                2580.730               0.000000   \n",
       "2                  2955.89                1477.945            1438.743097   \n",
       "3                  2814.40                1407.200            1722.229276   \n",
       "4                  3140.78                 628.156             256.421333   \n",
       "\n",
       "   monthly_out_count  monthly_out_total_amount  monthly_out_mean_amount  \\\n",
       "0                4.0                   2738.13                 684.5325   \n",
       "1                3.0                   1457.97                 485.9900   \n",
       "2                0.0                      0.00                   0.0000   \n",
       "3                0.0                      0.00                   0.0000   \n",
       "4                1.0                   2651.84                2651.8400   \n",
       "\n",
       "   monthly_out_std_amount                                   graph_embeddings  \n",
       "0              218.936394  [-7.4465707E-4,-5.0696253E-4,3.715253,5.235906...  \n",
       "1              222.568563  [-0.0,-0.0,23.231258,-0.0,20.905884,-0.0,19.88...  \n",
       "2                0.000000  [-0.0,17.563562,21.542643,23.562359,24.05239,2...  \n",
       "3                0.000000  [-0.027679602,4.8106894,4.7229276,-3.5944706E-...  \n",
       "4                0.000000  [-0.0,43.488667,45.72255,-0.0,40.119152,-0.0,-...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_transac_query.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Functions\n",
    "Transformation functions are a mathematical mapping of input data that may be stateful - requiring statistics from the partent feature view (such as number of instances of a category, or mean value of a numerical feature)\n",
    "\n",
    "We will preprocess our data using *min-max scaling* on numerical features and *label encoding* on categorical features. To do this we simply define a mapping between our features and transformation functions. This ensures that transformation functions such as *min-max scaling* are fitted only on the training data (and not the validation/test data), which ensures that there is no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "# Load built in transformation functions.\n",
    "min_max_scaler = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "\n",
    "# Map features to transformations.\n",
    "transformation_functions = {\n",
    "    \"monthly_in_count\": min_max_scaler,\n",
    "    \"monthly_in_total_amount\": min_max_scaler,\n",
    "    \"monthly_in_mean_amount\": min_max_scaler,\n",
    "    \"monthly_in_std_amount\": min_max_scaler,\n",
    "    \"monthly_out_count\": min_max_scaler,\n",
    "    \"monthly_out_total_amount\": min_max_scaler,\n",
    "    \"monthly_out_mean_amount\": min_max_scaler,\n",
    "    \"monthly_out_std_amount\": min_max_scaler\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation </span>\n",
    "\n",
    "In Hopsworks, you write features to feature groups (where the features are stored) and you read features from feature views. A feature view is a logical view over features, stored in feature groups, and a feature view typically contains the features used by a specific model. This way, feature views enable features, stored in different feature groups, to be reused across many different models. The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "In order to create a Feature View we may use `fs.create_feature_view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_view_non_sar = fs.get_feature_view('non_sar_transactions_view', 1)\n",
    "feature_view_non_sar = fs.create_feature_view(\n",
    "    name='non_sar_transactions_view',\n",
    "    query=non_sar_transac_query,\n",
    "    label=[\"is_sar\"],\n",
    "    transformation_functions=transformation_functions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_view_sar = fs.get_feature_view('sar_transactions_view', 1)\n",
    "feature_view_sar = fs.create_feature_view(\n",
    "    name='sar_transactions_view',\n",
    "    query=sar_transac_query,\n",
    "    label=[\"is_sar\"],\n",
    "    transformation_functions=transformation_functions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "Training dataset is created using `feature_view.create_training_dataset()()` method.\n",
    "\n",
    "**From feature view APIs we can also create training datasts based on even time filters specifing `start_time` and `end_time`** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset job started successfully, you can follow the progress at https://hopsworks0.logicalclocks.com/p/119/jobs/named/non_sar_transactions_view_1_3_create_fv_td_07062022162902/executions\n"
     ]
    }
   ],
   "source": [
    "td_non_sar_version, td_non_sar_job = feature_view_non_sar.create_training_dataset(\n",
    "    description = 'non sar training dataset',\n",
    "    data_format = 'tfrecord',\n",
    "    write_options = {'wait_for_job': True},\n",
    "    coalesce = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_sar_version, td_sar_job = feature_view_sar.create_training_dataset(\n",
    "    description = 'sar training dataset',\n",
    "    data_format = 'tfrecord',\n",
    "    write_options = {'wait_for_job': True},\n",
    "    coalesce = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ü™ù Training Dataset retreival </span>\n",
    "\n",
    "To retrieve training data from storage (already materialised) or from feature groups direcly we can use `get_training_dataset_splits` or `get_training_dataset` methods. If version is not provided or provided version has not already existed, it creates a new version of training data according to given arguments and returns a dataframe. If version is provided and has already existed, it reads training data from storage or feature groups and returns a dataframe. If split is provided, it reads the specific split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}