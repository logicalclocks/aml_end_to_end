{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training dataset for anomaly detection model\n",
    "In this notebook We are going to create training dataset from node embeddings feature group and register to Hopsworks Feature Store. \n",
    "![Training Dataset](./images/create_training_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a connection to hsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "from hops import hdfs\n",
    "# Create a connection\n",
    "connection = hsfs.connection()\n",
    "# Get the feature store handle for the project's feature store\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve alert nodes feature group from hsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alert_nodes_fg = fs.get_feature_group(\"alert_nodes_fg\", 1)\n",
    "transactions_fg = fs.get_feature_group(\"transactions_fg\", 1)\n",
    "alert_transactions_fg = fs.get_feature_group(\"alert_transactions_fg\", 1)\n",
    "node_embeddings_fg = fs.get_feature_group(\"node_embeddings_fg\", 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:54:28,062 INFO: USE `aml_demo_featurestore`\n",
      "2022-05-30 22:54:28,939 INFO: SELECT `fg1`.`source` `source`, `fg1`.`target` `target`, `fg1`.`tran_id` `tran_id`, `fg1`.`base_amt` `base_amt`, `fg1`.`tran_timestamp` `tran_timestamp`, `fg0`.`is_sar` `is_sar`\n",
      "FROM `aml_demo_featurestore`.`transactions_fg_1` `fg1`\n",
      "INNER JOIN `aml_demo_featurestore`.`alert_transactions_fg_1` `fg0` ON `fg1`.`tran_id` = `fg0`.`tran_id`\n"
     ]
    }
   ],
   "source": [
    "# create alert_nodes_fg, whether nodes were part of previously known money laundering scheme or not\n",
    "edges_with_labels = transactions_fg.select([\"source\",\"target\",\"tran_id\",\"base_amt\",\"tran_timestamp\"]).join(alert_transactions_fg.select([\"is_sar\"]),[\"tran_id\"],\"left\")\n",
    "edges_with_labels_pdf = edges_with_labels.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>tran_id</th>\n",
       "      <th>base_amt</th>\n",
       "      <th>tran_timestamp</th>\n",
       "      <th>is_sar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fa9657cd</td>\n",
       "      <td>b7c3ee5f</td>\n",
       "      <td>309059</td>\n",
       "      <td>2927.58</td>\n",
       "      <td>1596499200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f9660357</td>\n",
       "      <td>d5c32e28</td>\n",
       "      <td>310070</td>\n",
       "      <td>2443.28</td>\n",
       "      <td>1596499200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5cc91626</td>\n",
       "      <td>56e9fc25</td>\n",
       "      <td>569446</td>\n",
       "      <td>2715.63</td>\n",
       "      <td>1612224000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fd166006</td>\n",
       "      <td>7afc4353</td>\n",
       "      <td>929777</td>\n",
       "      <td>2916.66</td>\n",
       "      <td>1633996800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56eaa6a7</td>\n",
       "      <td>7afc4353</td>\n",
       "      <td>929776</td>\n",
       "      <td>2916.66</td>\n",
       "      <td>1633996800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     source    target  tran_id  base_amt  tran_timestamp  is_sar\n",
       "0  fa9657cd  b7c3ee5f   309059   2927.58   1596499200000       1\n",
       "1  f9660357  d5c32e28   310070   2443.28   1596499200000       1\n",
       "2  5cc91626  56e9fc25   569446   2715.63   1612224000000       1\n",
       "3  fd166006  7afc4353   929777   2916.66   1633996800000       1\n",
       "4  56eaa6a7  7afc4353   929776   2916.66   1633996800000       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_with_labels_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fa9657cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f9660357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5cc91626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fd166006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56eaa6a7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id\n",
       "0  fa9657cd\n",
       "1  f9660357\n",
       "2  5cc91626\n",
       "3  fd166006\n",
       "4  56eaa6a7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alert_edges = edges_with_labels_pdf[edges_with_labels_pdf.is_sar ==1]\n",
    "alert_edges.head()\n",
    "alert_sources = alert_edges[[\"source\"]]\n",
    "alert_sources.columns = [\"id\"]\n",
    "alert_sources.head()\n",
    "alert_targets = alert_edges[[\"target\"]]\n",
    "alert_targets.columns = [\"id\"]\n",
    "alert_nodes = alert_sources.append(alert_targets, ignore_index=True)\n",
    "alert_nodes = alert_nodes.drop_duplicates()\n",
    "alert_nodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training datasets for anomaly detection \n",
    "###### In the next notebook we are going to train [gan for anomaly detection](https://arxiv.org/pdf/1905.11034.pdf). Durring training step  we will provide only features of accounts that have never been reported for money laundering behaviour.  But we will disclose previously reported accounts to the model only in evaluation step.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_sar_emb_query = node_embeddings_fg.select([\"embedding\"])\\\n",
    "                                      .join(alert_nodes_fg.select([\"is_sar\"])\\\n",
    "                                      .filter(alert_nodes_fg.is_sar == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|           embedding|is_sar|\n",
      "+--------------------+------+\n",
      "|[-0.2894337177276...|     0|\n",
      "|[-0.8168580532073...|     0|\n",
      "|[0.89537668228149...|     0|\n",
      "|[0.55149841308593...|     0|\n",
      "|[0.28041338920593...|     0|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "non_sar_emb_query.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6531"
     ]
    }
   ],
   "source": [
    "non_sar_emb_query.read().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserWarning: Training dataset splits were defined but no `train_split` (the name of the split that is going to be used for training) was provided. Setting this property to `train`. The statistics of this split will be used for transformation functions."
     ]
    }
   ],
   "source": [
    "non_sar_td = fs.create_training_dataset(name=\"gan_non_sar_training_df\",\n",
    "                                       version=1,\n",
    "                                       data_format=\"tfrecord\",\n",
    "                                       label=[\"is_sar\"], \n",
    "                                       statistics_config={\"enabled\": False, \"histograms\": False, \"correlations\": False, \"exact_uniqueness\": False}, \n",
    "                                       splits={'train': 0.8, 'test': 0.2},\n",
    "                                       coalesce=True,\n",
    "                                       description=\"non sar dataset for gan training\")\n",
    "non_sar_td.save(non_sar_emb_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For testing and evaluation we will include known SAR nodes to measure anomaly score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_sar_td = fs.get_training_dataset(\"gan_non_sar_training_df\", 1)\n",
    "non_sar_test_df = non_sar_td.read(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_emb_query = node_embeddings_fg.select([\"embedding\"])\\\n",
    "                                  .join(alert_nodes_fg.select([\"is_sar\"])\\\n",
    "                                  .filter(alert_nodes_fg.is_sar == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|           embedding|is_sar|\n",
      "+--------------------+------+\n",
      "|[-0.9998507499694...|     0|\n",
      "|[-0.9986557960510...|     0|\n",
      "|[-0.9984421730041...|     0|\n",
      "|[-0.9970214366912...|     0|\n",
      "|[-0.9947502613067...|     0|\n",
      "|[-0.9934816360473...|     0|\n",
      "|[-0.9908211231231...|     0|\n",
      "|[-0.9882340431213...|     0|\n",
      "|[-0.9830579757690...|     0|\n",
      "|[-0.9823658466339...|     0|\n",
      "|[-0.9815602302551...|     0|\n",
      "|[-0.9814951419830...|     0|\n",
      "|[-0.9812114238739...|     0|\n",
      "|[-0.9809970855712...|     0|\n",
      "|[-0.9808425903320...|     0|\n",
      "|[-0.9780859947204...|     0|\n",
      "|[-0.9746136665344...|     0|\n",
      "|[-0.9715352058410...|     0|\n",
      "|[-0.9711296558380...|     0|\n",
      "|[-0.9682199954986...|     0|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "sar_df = sar_emb_query.read()\n",
    "sar_df = sar_df.select(*non_sar_test_df.columns)\n",
    "eval_df = non_sar_test_df.union(sar_df)\n",
    "eval_df.cache()\n",
    "eval_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1267"
     ]
    }
   ],
   "source": [
    "non_sar_test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816"
     ]
    }
   ],
   "source": [
    "sar_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2083"
     ]
    }
   ],
   "source": [
    "eval_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_eval_ds = fs.create_training_dataset(name=\"gan_eval_df\",\n",
    "                                       version=1,\n",
    "                                       data_format=\"tfrecord\",\n",
    "                                       label=[\"is_sar\"], \n",
    "                                       statistics_config={\"enabled\": False, \"histograms\": False, \"correlations\": False, \"exact_uniqueness\": False}, \n",
    "                                       coalesce = True,\n",
    "                                       description=\"evaluation dataset for gan training\")\n",
    "gan_eval_ds.save(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset provenance\n",
    "![Training dataset provenance](./images/provenance_td.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}